---
layout: archive
title: "Research Summary"
permalink: /research/
author_profile: true
---
In modern data centers, the network is playing a critical rule. The performance of the network is growing dramatically (e.g., from 1GbE in ~20 years ago to even 100GbE today). 
Also, emerging hardwares, such as FPGA and programmable ASIC, begin to power the network devices.
This brings us with two questions:

1. How can we enhance the existing system components (e.g., CPU, network stack) to let them carry the high-performance network more easily and efficiently?
2. How can we leverage the network itself to do more, and thus accelerate networked applications?

Our research tries to answer these two questions from multiple aspects.

For the first question, we not only consider the ways of better utilizing and managing existing hardware features (i.e., performance optimization and tuning) but also try to add new components (i.e., hardware accelerator) to further boost the performance of cloud applications and infrastructures.

For the second question, we explore the potential of in-network (both NIC and switch) computing and use distributed machine learning as a representative application to show the advantages of our ideas. 

We closely cooperate with industry (e.g., Intel) to guarantee that our research can be practical and feasible when solving real-world problems. 